---
title: "Chapter 8 - Tree Based Methods"
author: "Zhengting (Johnathan) He"
date: "2022/3/5"
output: html_document
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


# Fitting Classification Trees


```{r}
require(tree)
require(ISLR)
```


```{r}
attach(Carseats)
High <- factor(ifelse(Sales <= 8, "No", "Yes"))
```


```{r}
Carseats <- data.frame(Carseats, High)
```


```{r}
tree.carseats <- tree(High ~.-Sales, Carseats)
```


```{r}
summary(tree.carseats)
```


```{r}
plot(tree.carseats)
text(tree.carseats, pretty = 0)
```


```{r}
tree.carseats
```


```{r}
set.seed(2)
train <- sample(1:nrow(Carseats), 200)
Carseats.test <- Carseats[-train,]
High.test <- High[-train]
```


```{r}
tree.carseats <- tree(High ~ . -Sales, Carseats, subset = train)
tree.pred <- predict(tree.carseats, Carseats.test, type = "class")
table(tree.pred, High.test)
```


```{r}
(104+50)/200
```


```{r}
set.seed(3)
cv.carseats <- cv.tree(tree.carseats, FUN = prune.misclass)
names(cv.carseats)
```


```{r}
cv.carseats
```


```{r}
par(mfrow=c(1,2))
plot(cv.carseats$size, cv.carseats$dev, type = "b")
plot(cv.carseats$k, cv.carseats$dev, type = "b")
```


```{r}
prune.carseats <- prune.misclass(tree.carseats, best = 9)
plot(prune.carseats)
text(prune.carseats, pretty = 0)
```


```{r}
tree.pred <- predict(prune.carseats, Carseats.test, type = "class")
table(tree.pred, High.test)
```


```{r}
(97+58)/200
```


```{r}
prune.carseats <- prune.misclass(tree.carseats, best = 15)
plot(prune.carseats)
text(prune.carseats, pretty = 0)
```


```{r}
tree.pred <- predict(prune.carseats, Carseats.test, type = "class")
table(tree.pred, High.test)
```


```{r}
(102+53)/200
```


# Fitting Regression Trees


```{r}
require(MASS)
set.seed(1)
train <- sample(1:nrow(Boston), nrow(Boston)/2)
tree.boston <- tree(medv ~ ., Boston, subset = train)
summary(tree.boston)
```


```{r}
plot(tree.boston)
text(tree.boston, pretty = 0)
```


```{r}
cv.boston <- cv.tree(tree.boston)
plot(cv.boston$size, cv.boston$dev, type = "b")
```


```{r}
prune.boston <- prune.tree(tree.boston, best = 5)
plot(prune.boston)
text(prune.boston, pretty = 0)
```


```{r}
yhat <- predict(tree.boston, newdata = Boston[-train,])
boston.test <- Boston[-train, "medv"]
plot(yhat, boston.test)
abline(0,1)
```


```{r}
mean((yhat - boston.test)^2)
```


# Bagging and Random Forests


```{r}
require(randomForest)
set.seed(1)
bag.boston <- randomForest(medv ~ ., data = Boston, subset = train, mtry = 13, importance = TRUE)
bag.boston
```


```{r}
yhat.bag <- predict(bag.boston, newdata = Boston[-train,])
plot(yhat.bag, boston.test)
abline(0,1)
```


```{r}
mean((yhat.bag-boston.test)^2)
```


```{r}
bag.boston <- randomForest(medv ~ ., data = Boston, subset = train, mtry = 13, ntree = 25)
yhat.bag <- predict(bag.boston, newdata = Boston[-train,])
mean((yhat.bag-boston.test)^2)
```


```{r}
set.seed(1)
rf.boston <- randomForest(medv ~ ., data = Boston, subset = train, mtry = 6, importance = TRUE)
yhat.rf <- predict(rf.boston, newdata = Boston[-train,])
mean((yhat.bag-boston.test)^2)
```


```{r}
importance(rf.boston)
```


```{r}
varImpPlot(rf.boston)
```


# Boosting


```{r}
require(gbm)
set.seed(1)
boost.boston <- gbm(medv ~ ., data = Boston[train,], distribution = "gaussian",
                    n.trees = 5000, interaction.depth = 4)
```


```{r}
summary(boost.boston)
```


```{r}
par(mfrow=c(1,2))
plot(boost.boston, i = "rm")
plot(boost.boston, i = "lstat")
```


```{r}
yhat.boost <- predict(boost.boston, newdata = Boston[-train,], n.trees = 5000)
mean((yhat.bag-boston.test)^2)
```


```{r}
boost.boston <- gbm(medv ~ ., data = Boston[train,], distribution = "gaussian",
                    n.trees = 5000, interaction.depth = 4, shrinkage = 0.2, verbose = F)
yhat.boost <- predict(boost.boston, newdata = Boston[-train,], n.trees = 5000)
mean((yhat.bag-boston.test)^2)
```

